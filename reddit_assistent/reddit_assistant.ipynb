{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai python-dotenv praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the variables using os.getenv\n",
    "gpt4_azure_openai_endpoint = os.getenv(\"GPT4_AZURE_OPENAI_ENDPOINT\")\n",
    "gpt4_azure_openai_key = os.getenv(\"GPT4_AZURE_OPENAI_KEY\")\n",
    "gpt4_azure_openai_api_version = os.getenv(\"GPT4_AZURE_OPENAI_API_VERSION\")\n",
    "gpt4_deployment_name = os.getenv(\"GPT4_DEPLOYMENT_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant stuff\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from typing import Optional\n",
    "import json\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_message(\n",
    "    client: AzureOpenAI,\n",
    "    thread_id: str,\n",
    "    role: str = \"\",\n",
    "    content: str = \"\",\n",
    "    file_ids: Optional[list] = None,\n",
    "    metadata: Optional[dict] = None,\n",
    "    message_id: Optional[str] = None,\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    Create a message in a thread using the client.\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param role: Message role (user or assistant)\n",
    "    @param content: Message content\n",
    "    @param file_ids: Message file IDs\n",
    "    @param metadata: Message metadata\n",
    "    @param message_id: Message ID\n",
    "    @return: Message object\n",
    "\n",
    "    \"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    if file_ids is None:\n",
    "        file_ids = []\n",
    "\n",
    "    if client is None:\n",
    "        print(\"Client parameter is required.\")\n",
    "        return None\n",
    "\n",
    "    if thread_id is None:\n",
    "        print(\"Thread ID is required.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        if message_id is not None:\n",
    "            return client.beta.threads.messages.retrieve(thread_id=thread_id, message_id=message_id)\n",
    "\n",
    "        if file_ids is not None and len(file_ids) > 0 and metadata is not None and len(metadata) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, file_ids=file_ids, metadata=metadata\n",
    "            )\n",
    "\n",
    "        if file_ids is not None and len(file_ids) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, file_ids=file_ids\n",
    "            )\n",
    "\n",
    "        if metadata is not None and len(metadata) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, metadata=metadata\n",
    "            )\n",
    "\n",
    "        return client.beta.threads.messages.create(thread_id=thread_id, role=role, content=content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def poll_run_till_completion(\n",
    "    client: AzureOpenAI,\n",
    "    thread_id: str,\n",
    "    run_id: str,\n",
    "    available_functions: dict,\n",
    "    verbose: bool,\n",
    "    max_steps: int = 10,\n",
    "    wait: int = 3,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Poll a run until it is completed or failed or exceeds a certain number of iterations (MAX_STEPS)\n",
    "    with a preset wait in between polls\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param run_id: Run ID\n",
    "    @param assistant_id: Assistant ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param max_steps: Maximum number of steps to poll\n",
    "    @param wait: Wait time in seconds between polls\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if (client is None and thread_id is None) or run_id is None:\n",
    "        print(\"Client, Thread ID and Run ID are required.\")\n",
    "        return\n",
    "    try:\n",
    "        cnt = 0\n",
    "        while cnt < max_steps:\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "            if verbose:\n",
    "                print(\"Poll {}: {}\".format(cnt, run.status))\n",
    "            cnt += 1\n",
    "            if run.status == \"requires_action\":\n",
    "                tool_responses = []\n",
    "                if (\n",
    "                    run.required_action.type == \"submit_tool_outputs\"\n",
    "                    and run.required_action.submit_tool_outputs.tool_calls is not None\n",
    "                ):\n",
    "                    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "                    for call in tool_calls:\n",
    "                        if call.type == \"function\":\n",
    "                            if verbose:\n",
    "                                print(f\"Function call: {call.function.name}\")\n",
    "                            if call.function.name not in available_functions:\n",
    "                                raise Exception(\"Function requested by the model does not exist\")\n",
    "                            function_to_call = available_functions[call.function.name]\n",
    "                            tool_response = function_to_call(**json.loads(call.function.arguments))\n",
    "                            tool_responses.append({\"tool_call_id\": call.id, \"output\": tool_response})\n",
    "\n",
    "                run = client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread_id, run_id=run.id, tool_outputs=tool_responses\n",
    "                )\n",
    "            if run.status == \"failed\":\n",
    "                print(\"Run failed.\")\n",
    "                break\n",
    "            if run.status == \"completed\":\n",
    "                break\n",
    "            time.sleep(wait)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def retrieve_and_print_messages(\n",
    "    client: AzureOpenAI, thread_id: str, verbose: bool, out_dir: Optional[str] = None\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    Retrieve a list of messages in a thread and print it out with the query and response\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param out_dir: Output directory to save images\n",
    "    @return: Messages object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if client is None and thread_id is None:\n",
    "        print(\"Client and Thread ID are required.\")\n",
    "        return None\n",
    "    try:\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "        display_role = {\"user\": \"User query\", \"assistant\": \"Assistant response\"}\n",
    "\n",
    "        prev_role = None\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\\nCONVERSATION:\")\n",
    "        for md in reversed(messages.data):\n",
    "            if prev_role == \"assistant\" and md.role == \"user\" and verbose:\n",
    "                print(\"------ \\n\")\n",
    "\n",
    "            for mc in md.content:\n",
    "                # Check if valid text field is present in the mc object\n",
    "                if mc.type == \"text\":\n",
    "                    txt_val = mc.text.value\n",
    "                # Check if valid image field is present in the mc object\n",
    "                elif mc.type == \"image_file\":\n",
    "                    image_data = client.files.content(mc.image_file.file_id)\n",
    "                    if out_dir is not None:\n",
    "                        out_dir_path = Path(out_dir)\n",
    "                        if out_dir_path.exists():\n",
    "                            image_path = out_dir_path / (mc.image_file.file_id + \".png\")\n",
    "                            with image_path.open(\"wb\") as f:\n",
    "                                f.write(image_data.read())\n",
    "\n",
    "                if verbose:\n",
    "                    if prev_role == md.role:\n",
    "                        print(txt_val)\n",
    "                    else:\n",
    "                        print(\"{}:\\n{}\".format(display_role[md.role], txt_val))\n",
    "            prev_role = md.role\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tool array\n",
    "\n",
    "tools = []\n",
    "functions_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reddit\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import praw\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv(\"CLIENT_ID\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "user_agent = os.getenv(\"USER_AGENT\")\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "def subbmission_to_json(submission):\n",
    "    return {\n",
    "        \"title\": submission.title,\n",
    "        \"score\": submission.score,\n",
    "        \"id\": submission.id,\n",
    "        \"url\": submission.url,\n",
    "        \"num_comments\": submission.num_comments,\n",
    "        \"created\": submission.created,\n",
    "        \"selftext\": submission.selftext\n",
    "    }\n",
    "\n",
    "def get_reddit_posts(subreddit, limit):\n",
    "    hot_posts = reddit.subreddit(subreddit).hot(limit=limit)\n",
    "     \n",
    "    return json.dumps([subbmission_to_json(post) for post in hot_posts])\n",
    "\n",
    "# print(get_reddit_posts(\"python\", 5))\n",
    "\n",
    "def subreddit_search(keyword):\n",
    "    subs = reddit.subreddits.search_by_name(keyword, exact=False)\n",
    "    return json.dumps([sub.display_name for sub in subs])\n",
    "\n",
    "print(subreddit_search(\"python\"))\n",
    "\n",
    "#FUDNCTION DESCRIPTION\n",
    "top_subreddit_posts ={\n",
    "      \n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_reddit_posts\",\n",
    "        \"description\": \"Gets the top posts from a specified subreddit.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"subreddit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The subreddit to get posts from\",\n",
    "                },\n",
    "                \"limit\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of top posts to retrieve\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"subreddit\", \"limit\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tools.append(top_subreddit_posts)\n",
    "functions_map[\"get_reddit_posts\"] = get_reddit_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write file\n",
    "\n",
    "def write_to_file(filename, content):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "    return filename\n",
    "\n",
    "# Example usage:\n",
    "write_to_file('example.txt', 'Hello, world!')\n",
    "\n",
    "write_to_file_function = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"write_to_file\",\n",
    "        \"description\": \"Writes a given string into a file.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"filename\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the file to write to\",\n",
    "                },\n",
    "                \"content\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The string to write into the file\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"filename\", \"content\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tools.append(write_to_file_function)\n",
    "functions_map[\"write_to_file\"] = write_to_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_message(sub_reddit, limit=5):\n",
    "    return f\"Please write a newsletter about the {limit} most importnant topics from the {sub_reddit} subreddit? Please save the newsletter in a file {sub_reddit}_newsletter.md\"\n",
    "\n",
    "def get_assistant(sub_reddit, limit=5):\n",
    "    return  {\n",
    "        'name' : \"reddit_assistant\",\n",
    "        'instructions' : \"\"\"You are an assistant designed to help users getting an overview what happens on a subreddit.\n",
    "\n",
    "You have access to the subreddit api and create a newsletter like summary the top posts of a subreddit for the user.\n",
    "\"\"\",\n",
    "        'message': {\n",
    "            'role': 'user',\n",
    "            'content': get_message(sub_reddit, limit)\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_message(sub_reddit, limit=5):\n",
    "    return f\"Please write a newsletter about the {limit} most importnant topics from the {sub_reddit} subreddit? Please save the newsletter in a file {sub_reddit}_newsletter.md\"\n",
    "\n",
    "def get_assistant(sub_reddit, limit=5):\n",
    "    return  {\n",
    "        'name' : \"reddit_assistant\",\n",
    "        'instructions' : \"\"\"You are an assistant designed to help users getting an overview what happens on a subreddit.\n",
    "\n",
    "You have access to the subreddit api and create a newsletter like summary the top posts of a subreddit for the user.\n",
    "\"\"\",\n",
    "        'message': {\n",
    "            'role': 'user',\n",
    "            'content': get_message(sub_reddit, limit)\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_assistant(assistant_def, verbose_output):\n",
    "    client = AzureOpenAI(api_key=gpt4_azure_openai_key, api_version=gpt4_azure_openai_api_version, azure_endpoint=gpt4_azure_openai_endpoint)\n",
    "    assistant = client.beta.assistants.create(\n",
    "    name=assistant_def['name'], description=\"\", instructions=assistant_def['instructions'], tools=tools, model=gpt4_deployment_name)\n",
    "    thread = client.beta.threads.create()\n",
    "    create_message(client, thread.id, assistant_def['message'][\"role\"], assistant_def['message'][\"content\"])\n",
    "    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id, instructions=assistant_def['instructions'])\n",
    "    poll_run_till_completion(client=client, thread_id=thread.id, run_id=run.id, available_functions=functions_map, verbose=verbose_output, max_steps=50)\n",
    "    return retrieve_and_print_messages(client=client, thread_id=thread.id, verbose=verbose_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_def = get_assistant(\"german\", 10)\n",
    "\n",
    "verbose_output = True\n",
    "\n",
    "call_assistant(assistant_def, verbose_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
